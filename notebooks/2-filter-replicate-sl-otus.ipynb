{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is going to be used to create tables where supervised learning can be run to determine the most different OTUs between the replicates, as well as the runs as a whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":0: FutureWarning: IPython widgets are experimental and may change in the future.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from q2d2 import rarify\n",
    "from os.path import join\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.parallel import Client\n",
    "clients = Client(profile='data-analysis-conda')\n",
    "dview = clients.direct_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "home = '/home/office-microbe-files'\n",
    "notebooks = '/home/johnchase/office-project/office-microbes/notebooks'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load mapping file\n",
    "----------\n",
    "Load the mapping file and filter it to contain only 16S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map_fp = join(home, 'master_map_150908.txt')\n",
    "sample_md = pd.read_csv(map_fp, sep='\\t', index_col=0, dtype=str)\n",
    "sample_md = sample_md[sample_md['16SITS'] == '16S']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the two tables for run 1-3 and run 2-3\n",
    "----------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table_13 = pd.read_csv('table_13.txt', sep='\\t', index_col=0, dtype='object').astype('float')\n",
    "table_23 = pd.read_csv('table_23.txt', sep='\\t', index_col=0, dtype='object').astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rarify the tables and write to file\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rarify1000 = partial(rarify, even_sampling_depth=1000)\n",
    "df1, df2 = dview.map(rarify1000, [table_13, table_23])\n",
    "df1.to_csv('table_13_rarefied.txt', sep='\\t')\n",
    "df2.to_csv('table_23_rarefied.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "biom convert -i table_13_rarefied.txt -o table_13_rarefied.biom --table-type \"OTU table\" --to-hdf5\n",
    "biom convert -i table_23_rarefied.txt -o table_23_rarefied.biom --table-type \"OTU table\" --to-hdf5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run beta diversity on the full tables\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "parallel_beta_diversity.py -i /scratch/jc33/test_bdiv/tables/table_13_rarefied.biom -o /scratch/jc33/test_bdiv/output -t /scratch/jc33/beta_div/rep_set.tre  \n",
    "\n",
    "parallel_beta_diversity.py -i /scratch/jc33/test_bdiv/tables/table_23_rarefied.biom -o /scratch/jc33/test_bdiv/output23 -t /scratch/jc33/beta_div/rep_set.tre\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The replicate IDs are known. Although the replicate IDs could  be munged from the mapping file this will be faster and less error prone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#These are the replicate_ids\n",
    "replicate_ids = '''F2F.2.Ce.021\n",
    "F2F.2.Ce.022\n",
    "F2F.3.Ce.021\n",
    "F2F.3.Ce.022\n",
    "F2W.2.Ca.021\n",
    "F2W.2.Ca.022\n",
    "F2W.2.Ce.021\n",
    "F2W.2.Ce.022\n",
    "F3W.2.Ce.021\n",
    "F3W.2.Ce.022\n",
    "F1F.3.Ca.021\n",
    "F1F.3.Ca.022\n",
    "F1C.3.Ca.021\n",
    "F1C.3.Ca.022\n",
    "F1W.2.Ce.021\n",
    "F1W.2.Ce.022\n",
    "F1W.3.Dr.021\n",
    "F1W.3.Dr.022\n",
    "F1C.3.Dr.021\n",
    "F1C.3.Dr.022'''.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "office_md = sample_md[sample_md['OfficeSample'] == 'yes']\n",
    "office_md_13 = office_md[(office_md['Run'] == '1') | (office_md['Run'] == '3')]\n",
    "office_md_23 = office_md[(office_md['Run'] == '2') | (office_md['Run'] == '3')]\n",
    "reps_13 = office_md_13[office_md_13['Description'].isin(replicate_ids)]\n",
    "reps_23 = office_md_23[office_md_23['Description'].isin(replicate_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this seems redundant but is necessary to keep only duplicates we want\n",
    "reps_13 = reps_13[reps_13.duplicated('Description', keep='last') | reps_13.duplicated('Description')]\n",
    "reps_23 = reps_23[reps_23.duplicated('Description', keep='last') | reps_23.duplicated('Description')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "now we have the 10 replicates from each group of runs that we are interested in\n",
    "'F2F.3.Ce.022' was not included in the map from Argonne so there are only 9 run 2-3 replicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the unrarefied tables to include only the replicate samples\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table_13_replicates = table_13[reps_13.index]\n",
    "table_23_replicates = table_23[reps_23.index]\n",
    "table_13_replicates.to_csv('replicate_filtered_tables/table_13_replicates.txt', sep='\\t')\n",
    "table_23_replicates.to_csv('replicate_filtered_tables/table_23_replicates.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table_13_replicates_rarified = rarify1000(table_13_replicates)\n",
    "table_23_replicates_rarified = rarify1000(table_23_replicates)\n",
    "table_13_replicates_rarified.to_csv('replicate_filtered_tables/table_13_replicates_rarified.txt', sep='\\t')\n",
    "table_23_replicates_rarified.to_csv('replicate_filtered_tables/table_23_replicates_rarified.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run supervised learning on the resulting files\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "supervised_learning.py -i table_13_replicates_rarified.biom -m /home/office-microbe-files/master_map_150908.txt -c Run -o sl_13_out -e cv5  \n",
    "supervised_learning.py -i table_23_replicates_rarified.biom -m /home/office-microbe-files/master_map_150908.txt -c Run -o sl_23_out -e cv5\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load summary stats for sl \n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_13 = pd.read_csv('replicate_filtered_tables/sl_13_out/feature_importance_scores.txt', sep='\\t', index_col=0)\n",
    "feat_23 = pd.read_csv('replicate_filtered_tables/sl_23_out/feature_importance_scores.txt', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow to filter OTUs based on the blank samples included 10 samples from each run, 20 in total. So here we will also filter out 20, 200 and 2000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the tables at varying levels\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table_13_otus_10 = rarify(table_13.drop(feat_13.index[:20], inplace=False), 1000)\n",
    "table_13_otus_100 = rarify(table_13.drop(feat_13.index[:200], inplace=False), 1000)\n",
    "table_13_otus_1000 = rarify(table_13.drop(feat_13.index[:2000], inplace=False), 1000)\n",
    "\n",
    "table_23_otus_10 = rarify(table_23.drop(feat_23.index[:20], inplace=False), 1000)\n",
    "table_23_otus_100 = rarify(table_23.drop(feat_23.index[:200], inplace=False), 1000)\n",
    "table_23_otus_1000 = rarify(table_23.drop(feat_23.index[:2000], inplace=False), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "otus = [10, 100, 1000, 10, 100, 1000]\n",
    "runs = ['13']*3 + ['23']*3\n",
    "paths = [join(notebooks, 'blank_filtered_tables/table_{0}_otus_{1}.txt'.format(run, otu)) for run, otu in zip(runs, otus)]\n",
    "dfs = [table_13_otus_10, table_13_otus_100, table_13_otus_1000, \n",
    "       table_23_otus_10, table_23_otus_100, table_23_otus_1000]\n",
    "\n",
    "h = dview.map(df_to_file, dfs, paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the biom tables\n",
    "----------------\n",
    "\n",
    "```bash\n",
    "biom convert -i replicate_filtered_tables/filtered_tables/table_13_otus_10.txt -o replicate_filtered_tables/filtered_tables/table_13_otus_10.biom --to-hdf5 --table-type \"OTU table\"&\n",
    "biom convert -i replicate_filtered_tables/filtered_tables/table_13_otus_100.txt -o replicate_filtered_tables/filtered_tables/table_13_otus_100.biom --to-hdf5 --table-type \"OTU table\"&\n",
    "biom convert -i replicate_filtered_tables/filtered_tables/table_13_otus_1000.txt -o replicate_filtered_tables/filtered_tables/table_13_otus_1000.biom --to-hdf5 --table-type \"OTU table\"&\n",
    "biom convert -i replicate_filtered_tables/filtered_tables/table_23_otus_10.txt -o replicate_filtered_tables/filtered_tables/table_23_otus_10.biom --to-hdf5 --table-type \"OTU table\" &\n",
    "biom convert -i replicate_filtered_tables/filtered_tables/table_23_otus_100.txt -o replicate_filtered_tables/filtered_tables/table_23_otus_100.biom --to-hdf5 --table-type \"OTU table\"&\n",
    "biom convert -i replicate_filtered_tables/filtered_tables/table_23_otus_1000.txt -o replicate_filtered_tables/filtered_tables/table_23_otus_1000.biom --to-hdf5 --table-type \"OTU table\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run beta diversity\n",
    "---------------\n",
    "\n",
    "```bash\n",
    "#SBATCH --job-name=bd_sl\n",
    "#SBATCH --output=/scratch/jc33/bdiv/std_out.txt\n",
    "#SBATCH --error=/scratch/jc33/bdiv/std_err.txt\n",
    "#SBATCH --workdir=/scratch/jc33/beta_div\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --time=5-00:00:00\n",
    "#SBATCH --mem-per-cpu=32000\n",
    "\n",
    "module load qiime\n",
    "\n",
    "srun parallel_beta_diversity.py -i /scratch/jc33/bdiv/replicate_filtered_tables/filtered_tables/table_13_otus_10.biom -o /scratch/jc33/bdiv/replicate_filtered_tables/filtered_tables/bdiv_13_10_out -t /scratch/jc33/beta_div/rep_set.tre &  \n",
    "\n",
    "parallel_beta_diversity.py -i /scratch/jc33/bdiv/replicate_filtered_tables/filtered_tables/table_13_otus_100.biom -o /scratch/jc33/bdiv/replicate_filtered_tables/filtered_tables/bdiv_13_100_out -t /scratch/jc33/beta_div/rep_set.tre &  \n",
    "\n",
    "parallel_beta_diversity.py -i /scratch/jc33/bdiv/replicate_filtered_tables/filtered_tables/table_13_otus_1000.biom -o /scratch/jc33/bdiv/replicate_filtered_tables/filtered_tables/bdiv_13_1000_out -t /scratch/jc33/beta_div/rep_set.tre &  \n",
    "\n",
    "parallel_beta_diversity.py -i /scratch/jc33/bdiv/replicate_filtered_tables/filtered_tables/table_23_otus_10.biom -o /scratch/jc33/bdiv/replicate_filtered_tables/filtered_tables/bdiv_23_10_out -t /scratch/jc33/beta_div/rep_set.tre &  \n",
    "\n",
    "parallel_beta_diversity.py -i /scratch/jc33/bdiv/replicate_filtered_tables/filtered_tables/table_23_otus_100.biom -o /scratch/jc33/bdiv/replicate_filtered_tables/filtered_tables/bdiv_23_100_out -t /scratch/jc33/beta_div/rep_set.tre &  \n",
    "\n",
    "parallel_beta_diversity.py -i /scratch/jc33/bdiv/replicate_filtered_tables/filtered_tables/table_23_otus_1000.biom -o /scratch/jc33/bdiv/replicate_filtered_tables/filtered_tables/bdiv_23_1000_out -t /scratch/jc33/beta_div/rep_set.tre\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow\n",
    "-----------\n",
    "\n",
    "Unlike the previous example where I was looking at blanks I do want to rarefy the samples before comparing them. The idea being that in the blanks *anything* that was in the blanks should not have been there, whereas here we expect the composition to be relatively similar between replicates, however we want to rarefy so that we can compare them directly.\n",
    "\n",
    "1. Rarefy the full tables\n",
    "2. Compare the diffferences with beta diversity (this was done in the previous workflow)\n",
    "3. Filter tables to only contian replicate samples\n",
    "4. Compare these with supervised learning and/or differential abundance\n",
    "5. Filter out the top 10, 100, 1000 OTUs from the full table and rerun beta diversities\n",
    "\n",
    "Repeat the above steps, but this time compare the run to"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis-conda",
   "language": "python",
   "name": "auto_data-analysis-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
