{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":0: FutureWarning: IPython widgets are experimental and may change in the future.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from skbio import DistanceMatrix\n",
    "from os.path import join\n",
    "from skbio.stats.ordination import pcoa\n",
    "from q2d2 import rarify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.parallel import Client\n",
    "clients = Client(profile='data-analysis-conda')\n",
    "dview = clients.direct_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "home = '/home/office-microbe-files'\n",
    "notebooks = '/home/johnchase/office-project/office-microbes/notebooks'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Load mapping file\n",
    "----------\n",
    "Load the mapping file and filter it to contain only 16S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_fp = join(home, 'master_map_150908.txt')\n",
    "sample_md = pd.read_csv(map_fp, sep='\\t', index_col=0, dtype=str)\n",
    "sample_md = sample_md[sample_md['16SITS'] == '16S']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the full unrarefied OTU table\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table_fp = join(home, 'pick_otus_out_97/otu_table_mc2_w_tax_no_pynast_failures.txt')\n",
    "table = pd.read_csv(table_fp, sep='\\t', skiprows=1, index_col=0, dtype=\"object\")\n",
    "table.index = table.index.astype(str)\n",
    "table = table.astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter OTU table to be 1-3 and 2-3 samples only\n",
    "-------------------\n",
    "The first thing to do is to filter the OTU tables down into two different OTU tables, one that contains just run 1 and 2 samples, and another that only contains run 1 and 3. This is a bit weird, but these are the only combinations that have techincal replicates, and they don't overlap..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_1_3_ids = sample_md[(sample_md[\"Run\"] == \"1\") | (sample_md[\"Run\"] == \"3\")].index\n",
    "run_2_3_ids = sample_md[(sample_md[\"Run\"] == \"2\") | (sample_md[\"Run\"] == \"3\")].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many samples that are missing from the OTU table and I really don't understand why. There are other samples that are not missing with 0 sequences, so that shouldn't be the problem.  \n",
    "This is why there is the extra step if checking that the IDs are in the table before filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table_13 = table[run_1_3_ids[run_1_3_ids.isin(table.columns)]]\n",
    "table_23 = table[run_2_3_ids[run_2_3_ids.isin(table.columns)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These don't take too long to run, but others later will take quite a while so I'm defining a function here to run this in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df_to_file(df, filepath):\n",
    "    df.to_csv(filepath, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AsyncMapResult: df_to_file>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_fps = [join(notebooks, i) for i in ['table_13.txt', 'table_23.txt']]\n",
    "dview.map(df_to_file, [table_13, table_23], sample_fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find most abundant OTUs and rarefy the tables\n",
    "------------------\n",
    "While some of the OTUs may be overlappping in blanks the top ten of each will be filtered out, even if this means that only 17 of of 20 are unique for instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ids(sample_metadata, otu_table, run):\n",
    "    run_ids = sample_metadata[(sample_metadata['Run'] == run) & (sample_metadata['OfficeSample'] == 'no')].index\n",
    "    run_otus = otu_table[list(set(run_ids) & set(otu_table.columns))].sum(axis=1)\n",
    "    run_otus = run_otus.sort(ascending=False, inplace=False).index.tolist()\n",
    "    return run_otus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johnchase/.conda/envs/data-analysis/lib/python3.4/site-packages/IPython/kernel/__main__.py:4: FutureWarning: sort is deprecated, use sort_values(inplace=True) for for INPLACE sorting\n"
     ]
    }
   ],
   "source": [
    "run_1_otus = get_ids(sample_md, table, \"1\")\n",
    "run_2_otus = get_ids(sample_md, table, \"2\")\n",
    "run_3_otus = get_ids(sample_md, table, \"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table_13_otus_10 = rarify(table_13.drop(run_1_otus[:10] + run_3_otus[:10], inplace=False), 1000)\n",
    "table_13_otus_100 = rarify(table_13.drop(run_1_otus[:100] + run_3_otus[:100], inplace=False), 1000)\n",
    "table_13_otus_1000 = rarify(table_13.drop(run_1_otus[:1000] + run_3_otus[:1000], inplace=False), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table_23_otus_10 = rarify(table_23.drop(run_2_otus[:10] + run_3_otus[:10], inplace=False), 1000)\n",
    "table_23_otus_100 = rarify(table_23.drop(run_2_otus[:100] + run_3_otus[:100], inplace=False), 1000)\n",
    "table_23_otus_1000 = rarify(table_23.drop(run_2_otus[:1000] + run_3_otus[:1000], inplace=False), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir blank_filtered_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "otus = [10, 100, 1000, 10, 100, 1000]\n",
    "runs = ['13']*3 + ['23']*3\n",
    "paths = [join(notebooks, 'blank_filtered_tables/table_{0}_otus_{1}.txt'.format(run, otu)) for run, otu in zip(runs, otus)]\n",
    "dfs = [table_13_otus_10, table_13_otus_100, table_13_otus_1000, \n",
    "       table_23_otus_10, table_23_otus_100, table_23_otus_1000]\n",
    "\n",
    "h = dview.map(df_to_file, dfs, paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Convert all of the tables to biom to make them easier to work with\n",
    "----------------------\n",
    "\n",
    "```bash\n",
    "biom convert -i table_13.txt -o table_13.biom --to-hdf5 --table-type \"OTU table\"&  \n",
    "biom convert -i table_23.txt -o table_23.biom --to-hdf5 --table-type \"OTU table\"& \n",
    "biom convert -i blank_filtered_tables/table_13_otus_10.txt -o blank_filtered_tables/table_13_otus_10.biom --to-hdf5 --table-type \"OTU table\"&  \n",
    "biom convert -i blank_filtered_tables/table_13_otus_100.txt -o blank_filtered_tables/table_13_otus_100.biom --to-hdf5 --table-type \"OTU table\"&\n",
    "biom convert -i blank_filtered_tables/table_13_otus_1000.txt -o blank_filtered_tables/table_13_otus_1000.biom --to-hdf5 --table-type \"OTU table\"&  \n",
    "biom convert -i blank_filtered_tables/table_23_otus_10.txt -o blank_filtered_tables/table_23_otus_10.biom --to-hdf5 --table-type \"OTU table\" & \n",
    "biom convert -i blank_filtered_tables/table_23_otus_100.txt -o blank_filtered_tables/table_23_otus_100.biom --to-hdf5 --table-type \"OTU table\"&\n",
    "biom convert -i blank_filtered_tables/table_23_otus_1000.txt -o blank_filtered_tables/table_23_otus_1000.biom --to-hdf5 --table-type \"OTU table\"\n",
    "\n",
    "rm blank_filtered_tables/table_*_otus_*.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```bash\n",
    "#SBATCH --job-name=bd_all\n",
    "#SBATCH --output=/scratch/jc33/bdiv/std_out.txt\n",
    "#SBATCH --error=/scratch/jc33/bdiv/std_err.txt\n",
    "#SBATCH --workdir=/scratch/jc33/beta_div\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --time=2-00:00:00\n",
    "#SBATCH --mem-per-cpu=32000\n",
    "\n",
    "module load qiime\n",
    "\n",
    "srun parallel_beta_diversity.py -i /scratch/jc33/bdiv/table_13.biom -o /scratch/jc33/bdiv/bdiv_13 -t /scratch/jc33/bdiv/rep_set.tre &\n",
    "parallel_beta_diversity.py -i /scratch/jc33/bdiv/table_12.biom -o /scratch/jc33/bdiv/bdiv_12 -t /scratch/jc33/bdiv/rep_set.tre &\n",
    "\n",
    "parallel_beta_diversity.py -i /scratch/jc33/bdiv/blank_filtered_tables/table_13_otus_10.biom -o /scratch/jc33/bdiv/blank_filtered_tables/bdiv_13_10_out -t /scratch/jc33/beta_div/rep_set.tre &\n",
    "parallel_beta_diversity.py -i /scratch/jc33/bdiv/blank_filtered_tables/table_13_otus_100.biom -o /scratch/jc33/bdiv/blank_filtered_tables/bdiv_13_100_out -t /scratch/jc33/beta_div/rep_set.tre &\n",
    "parallel_beta_diversity.py -i /scratch/jc33/bdiv/blank_filtered_tables/table_13_otus_1000.biom -o /scratch/jc33/bdiv/blank_filtered_tables/bdiv_13_1000_out -t /scratch/jc33/beta_div/rep_set.tre &\n",
    "parallel_beta_diversity.py -i /scratch/jc33/bdiv/blank_filtered_tables/table_23_otus_10.biom -o /scratch/jc33/bdiv/blank_filtered_tables/bdiv_23_10_out -t /scratch/jc33/beta_div/rep_set.tre &\n",
    "parallel_beta_diversity.py -i /scratch/jc33/bdiv/blank_filtered_tables/table_23_otus_100.biom -o /scratch/jc33/bdiv/blank_filtered_tables/bdiv_23_100_out -t /scratch/jc33/beta_div/rep_set.tre &\n",
    "parallel_beta_diversity.py -i /scratch/jc33/bdiv/blank_filtered_tables/table_23_otus_1000.biom -o /scratch/jc33/bdiv/blank_filtered_tables/bdiv_23_1000_out -t /scratch/jc33/beta_div/rep_set.tre \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis-conda",
   "language": "python",
   "name": "auto_data-analysis-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
